{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.environ[\"OPENAI_API_KEY\"] = input(\"Enter OPENAI_API_KEY:\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "weave version 0.51.28 is available!  To upgrade, please run:\n",
      " $ pip install weave --upgrade\n",
      "Logged in as Weights & Biases user: xp20-hb.\n",
      "View Weave data at https://wandb.ai/highly-biased/test_final_v2/weave\n"
     ]
    }
   ],
   "source": [
    "import weave\n",
    "import json\n",
    "dataset=\"set1_test\"\n",
    "weave.init(f\"highly-biased/test_final_v2\")\n",
    "dataset_ref  = weave.ref(\"set1_test\").get()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = \"gpt-4o-mini-2024-07-18\"\n",
    "model = \"gpt-4o-2024-11-20\"\n",
    "# model = \"gpt-3.5-turbo-0125\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "jsonl = []\n",
    "\n",
    "for row in dataset_ref.rows:\n",
    "    jsonl.append(\n",
    "        {\"custom_id\": model + \"-\" + dataset + \"-\" + row[\"id\"],\n",
    "         \"method\": \"POST\", \n",
    "         \"url\": \"/v1/chat/completions\",\n",
    "         \"body\":{\n",
    "            \"model\":model,\n",
    "            \"messages\":[\n",
    "                {\n",
    "                \"role\": \"developer\",\n",
    "                \"content\": row[\"system_prompt\"]\n",
    "                },\n",
    "                {\n",
    "                \"role\": \"user\",\n",
    "                \"content\": row[\"user_prompt\"]\n",
    "                }            \n",
    "            ],\n",
    "            \"max_tokens\": 2000\n",
    "         }}\n",
    "    )\n",
    "with open(f\"openai-batch-files/{dataset_ref.name}-{model}.jsonl\", 'w') as f:\n",
    "    for item in jsonl:\n",
    "        f.write(json.dumps(item) + \"\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Upload the generated file to OpenAI and start a batch from the web interface**  \n",
    "(This is not done here, to prevent accidental execution)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from openai import OpenAI\n",
    "client = OpenAI()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Check status of Batch request:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_name = \"batch_6787c7331d8c8190afa976e613f1ffa5\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Batch(id='batch_6787c7331d8c8190afa976e613f1ffa5', completion_window='24h', created_at=1736951603, endpoint='/v1/chat/completions', input_file_id='file-6Kf2UDRpXi2KHukEifU3GA', object='batch', status='completed', cancelled_at=None, cancelling_at=None, completed_at=1736952074, error_file_id=None, errors=None, expired_at=None, expires_at=1737038003, failed_at=None, finalizing_at=1736951980, in_progress_at=1736951604, metadata={}, output_file_id='file-5bSL8ps9qGQWoVPCG9YHBv', request_counts=BatchRequestCounts(completed=720, failed=0, total=720))"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "batch_run = client.batches.retrieve(batch_name)\n",
    "batch_run"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "file_response = client.files.content(batch_run.output_file_id)\n",
    "with open(f\"openai-batch-files/output/{dataset_ref.name}-{model}-{batch_name}.jsonl\", 'w') as f:\n",
    "    f.write(file_response.text)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## jsonl to pandas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>custom_id</th>\n",
       "      <th>response.body.choices</th>\n",
       "      <th>response.body.usage.prompt_tokens</th>\n",
       "      <th>response.body.usage.completion_tokens</th>\n",
       "      <th>response.body.usage.total_tokens</th>\n",
       "      <th>response.body.model</th>\n",
       "      <th>content</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>batch_req_6786bd099e1c8190b9432a2bc01c3eae</td>\n",
       "      <td>gpt-4o-mini-2024-07-18-set1_test-0</td>\n",
       "      <td>[{'index': 0, 'message': {'role': 'assistant',...</td>\n",
       "      <td>57</td>\n",
       "      <td>1042</td>\n",
       "      <td>1099</td>\n",
       "      <td>gpt-4o-mini-2024-07-18</td>\n",
       "      <td>1. **Albert Einstein**:\\n   Albert Einstein (1...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>batch_req_6786bd09b2c48190a8d9453b65dc1f05</td>\n",
       "      <td>gpt-4o-mini-2024-07-18-set1_test-1</td>\n",
       "      <td>[{'index': 0, 'message': {'role': 'assistant',...</td>\n",
       "      <td>57</td>\n",
       "      <td>864</td>\n",
       "      <td>921</td>\n",
       "      <td>gpt-4o-mini-2024-07-18</td>\n",
       "      <td>### Albert Einstein\\nAlbert Einstein was a the...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>batch_req_6786bd09c7a88190beb002126d09d14b</td>\n",
       "      <td>gpt-4o-mini-2024-07-18-set1_test-2</td>\n",
       "      <td>[{'index': 0, 'message': {'role': 'assistant',...</td>\n",
       "      <td>57</td>\n",
       "      <td>1094</td>\n",
       "      <td>1151</td>\n",
       "      <td>gpt-4o-mini-2024-07-18</td>\n",
       "      <td>### 1. Albert Einstein\\nAlbert Einstein, born ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>batch_req_6786bd09e108819091a3355ae291a8a5</td>\n",
       "      <td>gpt-4o-mini-2024-07-18-set1_test-3</td>\n",
       "      <td>[{'index': 0, 'message': {'role': 'assistant',...</td>\n",
       "      <td>57</td>\n",
       "      <td>1103</td>\n",
       "      <td>1160</td>\n",
       "      <td>gpt-4o-mini-2024-07-18</td>\n",
       "      <td>Sure! Here’s a detailed description of each it...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                           id  \\\n",
       "0  batch_req_6786bd099e1c8190b9432a2bc01c3eae   \n",
       "1  batch_req_6786bd09b2c48190a8d9453b65dc1f05   \n",
       "2  batch_req_6786bd09c7a88190beb002126d09d14b   \n",
       "3  batch_req_6786bd09e108819091a3355ae291a8a5   \n",
       "\n",
       "                            custom_id  \\\n",
       "0  gpt-4o-mini-2024-07-18-set1_test-0   \n",
       "1  gpt-4o-mini-2024-07-18-set1_test-1   \n",
       "2  gpt-4o-mini-2024-07-18-set1_test-2   \n",
       "3  gpt-4o-mini-2024-07-18-set1_test-3   \n",
       "\n",
       "                               response.body.choices  \\\n",
       "0  [{'index': 0, 'message': {'role': 'assistant',...   \n",
       "1  [{'index': 0, 'message': {'role': 'assistant',...   \n",
       "2  [{'index': 0, 'message': {'role': 'assistant',...   \n",
       "3  [{'index': 0, 'message': {'role': 'assistant',...   \n",
       "\n",
       "   response.body.usage.prompt_tokens  response.body.usage.completion_tokens  \\\n",
       "0                                 57                                   1042   \n",
       "1                                 57                                    864   \n",
       "2                                 57                                   1094   \n",
       "3                                 57                                   1103   \n",
       "\n",
       "   response.body.usage.total_tokens     response.body.model  \\\n",
       "0                              1099  gpt-4o-mini-2024-07-18   \n",
       "1                               921  gpt-4o-mini-2024-07-18   \n",
       "2                              1151  gpt-4o-mini-2024-07-18   \n",
       "3                              1160  gpt-4o-mini-2024-07-18   \n",
       "\n",
       "                                             content  \n",
       "0  1. **Albert Einstein**:\\n   Albert Einstein (1...  \n",
       "1  ### Albert Einstein\\nAlbert Einstein was a the...  \n",
       "2  ### 1. Albert Einstein\\nAlbert Einstein, born ...  \n",
       "3  Sure! Here’s a detailed description of each it...  "
      ]
     },
     "execution_count": 79,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gpt_out_df = pd.read_json(f\"openai-batch-files/output/{dataset_ref.name}-{model}-{batch_name}.jsonl\", lines=True)\n",
    "gpt_out_df = pd.concat((gpt_out_df[[\"id\",\"custom_id\"]],\n",
    "                        pd.json_normalize(gpt_out_df[\"response\"]).add_prefix(\"response.\")[[\"response.body.choices\", \n",
    "                                                                                           \"response.body.usage.prompt_tokens\", \n",
    "                                                                                           \"response.body.usage.completion_tokens\",\n",
    "                                                                                           \"response.body.usage.total_tokens\",\n",
    "                                                                                           \"response.body.model\"\n",
    "                                                                                           ]]), \n",
    "                        axis=\"columns\")\n",
    "gpt_out_df[\"content\"] = gpt_out_df[\"response.body.choices\"].apply(lambda response: response[0][\"message\"][\"content\"])\n",
    "gpt_out_df"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "SocialMediaMining2",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
